{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Word Embeddings Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the necessary libraries..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "And we need to initiate a Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('word-embeddings-demo').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Data preparation\n",
    "\n",
    "The Reuters corpus is a collection of news documents. It contains over 10,000 news documents totaling over 1.3 million words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This Reuters corpus was loaded from Python's `NLTK` package and preprocessed using `NLTK` in the following ways:\n",
    "\n",
    "  * Removing punctuation\n",
    "  * Lemmatizing each word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The data was imported into Spark and saved as a single-field document-level parquet file for this demonstration which is reloaded below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "reuters_df = spark.read.parquet('data/reuters-train-corpus.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Some basic information about `reuters_df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13328, 1]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[reuters_df.count(), len(reuters_df.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reuters_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|[u, k, money, mar...|\n",
      "|[u, k, money, mar...|\n",
      "|[south, korea, to...|\n",
      "|[u, k, money, mar...|\n",
      "|[u, s, treasury, ...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reuters_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Creating and fitting the model\n",
    "\n",
    "When using Spark's `Word2Vec` functionality, we need to first instantiate a `Word2Vec` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "reuters_word2vec = Word2Vec(\n",
    "    vectorSize = 100, windowSize = 5, inputCol = 'value', \n",
    "    outputCol = 'embedding', seed = 6231912\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "There are a couple key parameters here:\n",
    "\n",
    "  * `vectorSize` - the desired dimension of the output vector\n",
    "  * `windowSize` - the number of words in the context window\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "And there are a few others that we'll leave be for now: `maxSentenceLength`, `maxIter`, `stepSize`, `numPartitions`, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can then fit a model on the Reuters corpus using `Word2Vec`'s `fit` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "reuters_model = reuters_word2vec.fit(reuters_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The resulting `reuters_model` object is the trained model containing the word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Demo 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The `Word2VecModel`'s `findSynonyms(word, num)` method finds the `num` most similar words to `word` using cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|   word|        similarity|\n",
      "+-------+------------------+\n",
      "|  italy|0.7977195978164673|\n",
      "|belgium|0.7509787678718567|\n",
      "|denmark|0.7170287370681763|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reuters_model.findSynonyms('spain', 3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+\n",
      "|    word|        similarity|\n",
      "+--------+------------------+\n",
      "|chairman|0.6982269883155823|\n",
      "|    vice|0.6736516952514648|\n",
      "|   chief|0.6535186767578125|\n",
      "+--------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reuters_model.findSynonyms('president', 3).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "And we can use the following to set up the equation to solve for the fourth word:\n",
    "\n",
    "* $Father - Mother + Grandmother = Grandfather$\n",
    "* $Lose - Win + Rise = Fall$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The following function estimates the fourth word by: \n",
    "\n",
    "  1. Taking the first three words and the model as input\n",
    "  2. Finding the vectors of the three words according to the model\n",
    "  3. Computing the fourth vector using the equation previously outlined\n",
    "  4. Finding the words in the model's vocabulary that are closest to the fourth vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def getAnalogy(model, word1, word2, word3):\n",
    "    \n",
    "    from pyspark.sql.functions import col\n",
    "    \n",
    "    embeddings_df = model.getVectors()\n",
    "    word1_vector = embeddings_df.filter(col('word') == word1).select('vector').collect()[0][0] \n",
    "    word2_vector = embeddings_df.filter(col('word') == word2).select('vector').collect()[0][0]\n",
    "    word3_vector = embeddings_df.filter(col('word') == word3).select('vector').collect()[0][0]\n",
    "        \n",
    "    return model \\\n",
    "        .findSynonyms(word2_vector - word1_vector + word3_vector, 4) \\\n",
    "        .filter(col('word') != word3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The analogy below tries to solve the following equation:\n",
    "\n",
    "$$Lose - Win + Rise = \\hspace{2mm}\\rule{1.5cm}{0.15mm}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|   word|        similarity|\n",
      "+-------+------------------+\n",
      "|decline|0.6982008218765259|\n",
      "|   fall|0.6950353980064392|\n",
      "|   drop| 0.681812047958374|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "getAnalogy(reuters_model, 'win', 'lose', 'rise').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "While *fall* isn't the top result, it's close and all of the words carry a similar meaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Demo 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Syntactic relationships are harder to learn and require a large amount of data when creating the word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We'll load in pre-trained word embeddings developed by Google:\n",
    "\n",
    "  * These are again based on news documents \n",
    "  * There are over 3 billion words included in the training corpus and 3 million words with vectors\n",
    "  * Note that these are loaded in using `gensim` package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "google_embeddings = KeyedVectors.load_word2vec_format('data/GoogleNews-vectors-negative300.bin', binary = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The same analogy framework used to show semantic relationships can be used to show these syntactic relationships\n",
    "\n",
    "* $Add - Added = Substract - Subtracted$\n",
    "* $Run - Ran = Shrink - \\hspace{2mm}\\rule{1.5cm}{0.15mm}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A new analogy function is required due to the use of `gensim` rather than Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def getAnalogyGensim(embeddings, word1, word2, word3):\n",
    "        \n",
    "    word1_vector = embeddings.get_vector(word1)\n",
    "    word2_vector = embeddings.get_vector(word2)\n",
    "    word3_vector = embeddings.get_vector(word3)\n",
    "        \n",
    "    return [\n",
    "        element for element in embeddings.similar_by_word(word2_vector - word1_vector + word3_vector, 5) \n",
    "        if element[0] != word3\n",
    "    ]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('subtracted', 0.6371101140975952),\n",
       " ('subtracting', 0.5363016128540039),\n",
       " ('subtracts', 0.5089912414550781),\n",
       " ('deducted', 0.4715757668018341)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getAnalogyGensim(google_embeddings, 'add', 'added', 'subtract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hung', 0.7027653455734253),\n",
       " ('hanging', 0.6336132287979126),\n",
       " ('ran', 0.6057102680206299),\n",
       " ('hangs', 0.5554769039154053)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getAnalogyGensim(google_embeddings, 'run', 'ran', 'hang')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Plurality\n",
    "\n",
    "Plurality can also be represented in word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dogs', 0.9074791669845581),\n",
       " ('cats', 0.7861816883087158),\n",
       " ('pets', 0.7557172775268555),\n",
       " ('canines', 0.7553417682647705)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getAnalogyGensim(google_embeddings, 'cat', 'cats', 'dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('geese', 0.7856709957122803),\n",
       " ('ducks', 0.702297031879425),\n",
       " ('Canada_geese', 0.6364935636520386),\n",
       " ('mallards', 0.6159207224845886)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getAnalogyGensim(google_embeddings, 'duck', 'ducks', 'goose')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('elk', 0.7245393991470337),\n",
       " ('caribou', 0.7196517586708069),\n",
       " ('deer', 0.7054836750030518),\n",
       " ('grizzlies', 0.6522204875946045)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getAnalogyGensim(google_embeddings, 'dog', 'dogs', 'moose')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tableaux', 0.6940608620643616),\n",
       " ('tableaus', 0.6453362703323364),\n",
       " ('tableau_vivant', 0.5498777031898499),\n",
       " ('tableaux_vivants', 0.5395413637161255)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getAnalogyGensim(google_embeddings, 'dog', 'dogs', 'tableau')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Demo 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+\n",
      "|        word|        similarity|\n",
      "+------------+------------------+\n",
      "|  electronic|0.6784631013870239|\n",
      "|manufactured|0.5808244943618774|\n",
      "|  electrical|0.4770793318748474|\n",
      "+------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reuters_model.findSynonyms('good', 3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|     word|        similarity|\n",
      "+---------+------------------+\n",
      "|  entitle|0.6891614198684692|\n",
      "| entitles| 0.643031895160675|\n",
      "|entitling|0.6147499680519104|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reuters_model.findSynonyms('right', 3).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "These definitions are based on how the words are used in the Reuters corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's look at these same words using word embeddings created using the Gutenberg corpus &mdash; a collection of novels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# gutenberg_df = spark.read.parquet('data/gutenberg-train-corpus.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# gutenberg_word2vec = Word2Vec(\n",
    "#     vectorSize = 300, windowSize = 10, inputCol = 'value', \n",
    "#     outputCol = 'embedding', seed = 6231912, maxSentenceLength = 2000, maxIter = 5\n",
    "# )\n",
    "# gutenberg_model = gutenberg_word2vec.fit(gutenberg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gutenberg_model.save(\"data/gutenberg_model.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Word2VecModel\n",
    "gutenberg_model = Word2VecModel.load(\"data/gutenberg_model.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The resulting synonyms represent different definitions of the words than the Reuters corpus embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|   word|        similarity|\n",
      "+-------+------------------+\n",
      "|natured|0.5722174644470215|\n",
      "|   much|0.5657753944396973|\n",
      "|   well|0.5315241813659668|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gutenberg_model.findSynonyms('good', 3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+\n",
      "|     word|         similarity|\n",
      "+---------+-------------------+\n",
      "|     left| 0.3864390254020691|\n",
      "|admirably| 0.3837079703807831|\n",
      "|   decide|0.37801557779312134|\n",
      "+---------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gutenberg_model.findSynonyms('right', 3).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Most word embedding algorithms require a large amount of data to create successful results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|   word|        similarity|\n",
      "+-------+------------------+\n",
      "|  jerry| 0.668878436088562|\n",
      "|muskrat|0.6316283345222473|\n",
      "| anyway|0.6198262572288513|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "getAnalogy(gutenberg_model, 'father', 'mother', 'grandfather').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('grandmother', 0.8793414831161499),\n",
       " ('aunt', 0.8139014840126038),\n",
       " ('mother', 0.8082102537155151),\n",
       " ('granddaughter', 0.7867908477783203)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getAnalogyGensim(google_embeddings, 'father', 'mother', 'grandfather')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "word-embeddings-wwh",
   "language": "python",
   "name": "word-embeddings-wwh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "rise": {
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
